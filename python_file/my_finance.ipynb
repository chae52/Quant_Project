{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_finance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA1GO9uXC1Xr"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense,LSTM, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from tensorflow import keras\n",
        "from keras import models, layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJcz071fw1RO"
      },
      "source": [
        "def change_time(time_str):\n",
        "    time_str = str(time_str)\n",
        "    return time_str[:4] + '/'+time_str[4:6] + '/' + time_str[6:]\n",
        "\n",
        "def make_time(date_str):\n",
        "    a = date_str.split(\" \")\n",
        "    t = a[0][:-1]+\"/\"+a[1][:-1]+\"/\"+a[2][:-1]\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOk5NufPoK9G"
      },
      "source": [
        "high_yield = pd.read_csv(\"/content/drive/MyDrive/predict_price/high_yield.csv\")\n",
        "high_yield = high_yield.drop(high_yield[high_yield['BAMLH0A0HYM2'] == '.'].index)\n",
        "high_yield['DATE'] = pd.to_datetime(high_yield['DATE'])\n",
        "\n",
        "dollar_index = pd.read_csv(\"/content/drive/MyDrive/predict_price/dollar_index.csv\")[['Date', 'Close']]\n",
        "dollar_index['Date'] = pd.to_datetime(dollar_index['Date'])\n",
        "krw = pd.read_csv(\"/content/drive/MyDrive/predict_price/krw.csv\")[['Date','Close']]\n",
        "krw['Date'] = pd.to_datetime(krw['Date'])\n",
        "tnx = pd.read_csv(\"/content/drive/MyDrive/predict_price/^TNX.csv\")[['Date', 'Close']]\n",
        "tnx['Date'] = pd.to_datetime(tnx['Date'])\n",
        "apply_data = pd.read_csv(\"/content/drive/MyDrive/predict_price/apply_data.csv\")\n",
        "apply_data['date'] = pd.to_datetime(apply_data['date'])\n",
        "\n",
        "china = pd.read_csv(\"/content/drive/MyDrive/predict_price/sanhai.csv\")[['날짜','종가']]\n",
        "china['날짜'] = china['날짜'].apply(make_time)\n",
        "china['날짜'] = pd.to_datetime(china['날짜'])\n",
        "china['종가'] = china['종가'].apply(lambda x : x.replace(\",\",\"\"))\n",
        "china['종가'] = pd.to_numeric(china['종가'])\n",
        "america = pd.read_csv(\"/content/drive/MyDrive/predict_price/america.csv\")[['날짜','종가']]\n",
        "america['날짜'] = america['날짜'].apply(make_time)\n",
        "america['날짜'] = pd.to_datetime(america['날짜'])\n",
        "america['종가'] = america['종가'].apply(lambda x : x.replace(\",\",\"\"))\n",
        "america['종가'] = pd.to_numeric(america['종가'])\n",
        "wti = pd.read_csv('/content/drive/MyDrive/predict_price/wti.csv')[['날짜','종가']]\n",
        "wti['날짜'] = wti['날짜'].apply(make_time)\n",
        "wti['날짜'] = pd.to_datetime(wti['날짜'])\n",
        "wti['종가'] = pd.to_numeric(wti['종가'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khz7SQw4tSIt"
      },
      "source": [
        "price = os.listdir(\"/content/drive/MyDrive/창의학기제/real_final_data\")\n",
        "\n",
        "for src in price[1:]:\n",
        "    data = pd.read_csv(f'/content/drive/MyDrive/창의학기제/real_final_data/{src}')\n",
        "    data = data.set_index('Date')\n",
        "    scaler = MinMaxScaler()\n",
        "    data_processing = scaler.fit_transform(data)\n",
        "    data_processing = pd.DataFrame(data_processing)\n",
        "\n",
        "    X_l = []\n",
        "    y_l = []\n",
        "    N = len(data_processing)\n",
        "    D = 5\n",
        "    for i in range(N-D-1):\n",
        "        X_l.append(data_processing.iloc[i:i+D])\n",
        "        y_l.append(data_processing[0].iloc[i+D])\n",
        "    X = np.array(X_l)\n",
        "    y = np.array(y_l)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(20,input_shape=X.shape[1:]))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Dense(1))\n",
        "    model.compile('adam','mse')\n",
        "    history = model.fit(X,y, batch_size=64, epochs=100, validation_split=0.3,verbose=1)\n",
        "    print(f\"{price_src} - va_loss : \", history.history['val_loss'][-1])\n",
        "    model.save(f'/content/drive/MyDrive/real_final/{src}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUx1z821uxs8"
      },
      "source": [
        "for price_src in price:\n",
        "    print(price_src)\n",
        "    data = pd.read_csv(f\"/content/drive/MyDrive/price_data/{price_src}\")[['Date','Close']]\n",
        "    # data['Date'] = data['Date'].apply(change_time)\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data = pd.merge(data, high_yield, left_on='Date', right_on='DATE',).drop('DATE',axis=1)\n",
        "    data = pd.merge(data,dollar_index, on ='Date')\n",
        "    data = pd.merge(data, krw ,on ='Date')\n",
        "    data = pd.merge(data, tnx, on=\"Date\")\n",
        "    data = pd.merge(data, apply_data, left_on='Date', right_on='date').drop('date',axis=1)\n",
        "    data = pd.merge(data, china, left_on='Date', right_on='날짜').drop('날짜',axis=1)\n",
        "    data = pd.merge(data, america, left_on='Date', right_on='날짜').drop('날짜',axis=1)\n",
        "    data = pd.merge(data, wti, left_on='Date', right_on='날짜').drop('날짜',axis=1)\n",
        "\n",
        "    data.columns = ['Date','price','high_yield','dollar_index','krw','tnx','organization','foreigner','china','america','wti']\n",
        "    data = data[1:]\n",
        "\n",
        "    if len(data) <= 365 * 3:\n",
        "        continue\n",
        "\n",
        "    control_columns_null = data.columns[2:]\n",
        "\n",
        "    for c in control_columns_null:\n",
        "        for i in data[data[c].isnull()].index:\n",
        "            data.loc[i,c] = data.loc[i-1,c]\n",
        "    data.to_csv(f\"{price_src}\",index= None)\n",
        "    data = data.set_index('Date')\n",
        "    tmp =price_src.split(\"_\")[0]\n",
        "    data.to_csv(f\"/content/drive/MyDrive/price_data/{tmp}.csv\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJcp1--K-UTY"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "data_processing = scaler.fit_transform(np.array(data))\n",
        "data_processing = pd.DataFrame(data_processing)\n",
        "\n",
        "X_l = []\n",
        "y_l = []\n",
        "N = len(data_processing)\n",
        "D = 5\n",
        "for i in range(N-D-1):\n",
        "    X_l.append(data_processing.iloc[i:i+D])\n",
        "    y_l.append(data_processing[0].iloc[i+D])\n",
        "X = np.array(X_l)\n",
        "y = np.array(y_l)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(20,input_shape=X.shape[1:]))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile('adam','mse')\n",
        "history = model.fit(X,y, batch_size=64, epochs=200, validation_split=0.3,verbose=0)\n",
        "print(f\"{price_src} - va_loss : \", history.history['val_loss'][-1])\n",
        "model.save(f'/content/drive/MyDrive/model_file/{price_src}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpoTdKWKw8LJ"
      },
      "source": [
        "price = os.listdir(\"/content/drive/MyDrive/predict_price/price\")\n",
        "\n",
        "for price_src in price:\n",
        "    data = pd.read_csv(f\"/content/drive/MyDrive/price_data/{price_src}\")\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    data_processing = scaler.fit_transform(np.array(data))\n",
        "    data_processing = pd.DataFrame(data_processing)\n",
        "\n",
        "    X_l = []\n",
        "    y_l = []\n",
        "    N = len(data_processing)\n",
        "    D = 5\n",
        "    for i in range(N-D-1):\n",
        "        X_l.append(data_processing.iloc[i:i+D])\n",
        "        y_l.append(data_processing[0].iloc[i+D])\n",
        "    X = np.array(X_l)\n",
        "    y = np.array(y_l)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(20,input_shape=X.shape[1:]))\n",
        "    model.add(Dense(10,activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile('adam','mse')\n",
        "    history = model.fit(X,y, batch_size=64, epochs=200, validation_split=0.3,verbose=0)\n",
        "    print(f\"{price_src} - va_loss : \", history.history['val_loss'][-1])\n",
        "    model.save(f'/content/drive/MyDrive/model_file/{price_src}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ1doJUyya2Y"
      },
      "source": [
        "logo_time = os.listdir(\"/content/drive/MyDrive/predict_price/price\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooz2_motyh7P"
      },
      "source": [
        "logo_name = [*map(lambda x : x[:-4],logo_time)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kaioPDCgPff"
      },
      "source": [
        "logo_name = [*map(lambda x : x.split(\"_\"), logo_name)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q2pbPk8gmpt"
      },
      "source": [
        "stock_list = {}\n",
        "for code, name in logo_name:\n",
        "    stock_list[code] = name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASlxALgTZWsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18247f8-2b0f-4bab-c7e5-d2ab1526ab05"
      },
      "source": [
        "models_h5 = os.listdir('/content/drive/MyDrive/model_h5')\n",
        "price_data = os.listdir('/content/drive/MyDrive/price_data')\n",
        "arr = []\n",
        "\n",
        "for mod in models_h5:\n",
        "    data = pd.read_csv(f\"/content/drive/MyDrive/price_dataset/{mod.split('.')[0]}.csv\")\n",
        "    scaler = MinMaxScaler()\n",
        "    data = data[data.columns[1:]]\n",
        "    data_processing = scaler.fit_transform(np.array(data))\n",
        "    data_processing = pd.DataFrame(data_processing)\n",
        "    new_model = models.load_model(f'/content/drive/MyDrive/model_h5/{mod}')\n",
        "\n",
        "    a= new_model.predict(np.array(data_processing[-6:-1]).reshape(-1,5,10))\n",
        "    va = (a - data_processing.iloc[-2][0])/ data_processing.iloc[-2][0] * 100\n",
        "\n",
        "    if -5 <= va <= 5:\n",
        "        print(stock_list[mod.split(\".\")[0]],\" : \",round(float(va),2))\n",
        "        arr.append([stock_list[mod.split(\".\")[0]],round(float(va),2)])\n",
        "    elif -50<= va <= -5 or 5 <= va <=50:\n",
        "        print(stock_list[mod.split(\".\")[0]],\" : \",round(float(va)/10,2) )\n",
        "        arr.append([stock_list[mod.split(\".\")[0]],round(float(va)/10,2)])\n",
        "    else:\n",
        "        print(stock_list[mod.split(\".\")[0]],\" : \",round(float(va)/100,2))\n",
        "        arr.append([stock_list[mod.split(\".\")[0]],round(float(va)/100,2)])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LG  :  0.97\n",
            "쌍용C&E  :  -1.23\n",
            "대한항공  :  -1.29\n",
            "아모레G  :  4.05\n",
            "삼성화재  :  2.42\n",
            "현대건설  :  -1.06\n",
            "SK하이닉스  :  2.19\n",
            "기아  :  0.03\n",
            "CJ대한통운  :  3.66\n",
            "유한양행  :  -1.69\n",
            "현대모비스  :  -1.43\n",
            "금호석유  :  -2.06\n",
            "SKC  :  -3.19\n",
            "HMM  :  -1.11\n",
            "롯데케미칼  :  1.67\n",
            "LG이노텍  :  -1.07\n",
            "S-Oil  :  1.15\n",
            "현대미포조선  :  0.79\n",
            "삼성중공업  :  -0.54\n",
            "고려아연  :  0.74\n",
            "한화솔루션  :  -0.72\n",
            "한국조선해양  :  -1.38\n",
            "삼성전기  :  -0.59\n",
            "한미사이언스  :  4.96\n",
            "호텔신라  :  -0.64\n",
            "메리츠증권  :  -0.91\n",
            "GS리테일  :  -2.5\n",
            "미래에셋증권  :  -0.66\n",
            "삼성SDI  :  -3.9\n",
            "녹십자  :  -0.95\n",
            "NH투자증권  :  -0.67\n",
            "GS건설  :  -2.23\n",
            "삼성전자  :  -5.52\n",
            "DB손해보험  :  0.97\n",
            "POSCO  :  -3.11\n",
            "현대차  :  -1.11\n",
            "롯데지주  :  0.69\n",
            "현대제철  :  -1.14\n",
            "포스코케미칼  :  0.26\n",
            "한국전력  :  -1.91\n",
            "SK텔레콤  :  -4.18\n",
            "삼성증권  :  -0.9\n",
            "삼성에스디에스  :  -2.28\n",
            "삼성엔지니어링  :  -0.55\n",
            "LG유플러스  :  -0.77\n",
            "삼성카드  :  -2.63\n",
            "KT  :  -2.9\n",
            "팬오션  :  -0.25\n",
            "일진머티리얼즈  :  -1.23\n",
            "삼성물산  :  -1.3\n",
            "기업은행  :  4.02\n",
            "신풍제약  :  -1.37\n",
            "한온시스템  :  0.75\n",
            "코웨이  :  4.16\n",
            "SK이노베이션  :  -1.03\n",
            "아모레퍼시픽  :  -0.62\n",
            "맥쿼리인프라  :  -1.02\n",
            "현대글로비스  :  -4.53\n",
            "하나금융지주  :  -2.13\n",
            "휠라홀딩스  :  2.76\n",
            "GS  :  0.6\n",
            "한국금융지주  :  -4.61\n",
            "셀트리온  :  1.73\n",
            "LG전자  :  -4.56\n",
            "신한지주  :  -1.12\n",
            "LG화학  :  -0.64\n",
            "LG생활건강  :  4.12\n",
            "한국항공우주  :  1.37\n",
            "대우건설  :  -1.35\n",
            "엔씨소프트  :  -1.87\n",
            "대우조선해양  :  -0.65\n",
            "한국가스공사  :  -1.09\n",
            "카카오  :  3.23\n",
            "NAVER  :  0.55\n",
            "강원랜드  :  -0.63\n",
            "SK  :  1.48\n",
            "KT&G  :  1.67\n",
            "LG디스플레이  :  2.75\n",
            "두산중공업  :  -1.61\n",
            "삼성생명  :  -1.69\n",
            "한진칼  :  -1.02\n",
            "두산밥캣  :  -1.49\n",
            "삼성바이오로직스  :  -2.17\n",
            "이마트  :  -0.87\n",
            "한미약품  :  1.26\n",
            "CJ제일제당  :  -3.03\n",
            "KB금융  :  0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPo8s8sS9ZVn",
        "outputId": "7adccb85-cbd4-4dc7-fa99-e10b99cb82c3"
      },
      "source": [
        "arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['LG', 0.97],\n",
              " ['쌍용C&E', -1.23],\n",
              " ['대한항공', -1.29],\n",
              " ['아모레G', 4.05],\n",
              " ['삼성화재', 2.42],\n",
              " ['현대건설', -1.06],\n",
              " ['SK하이닉스', 2.19],\n",
              " ['기아', 0.03],\n",
              " ['CJ대한통운', 3.66],\n",
              " ['유한양행', -1.69],\n",
              " ['현대모비스', -1.43],\n",
              " ['금호석유', -2.06],\n",
              " ['SKC', -3.19],\n",
              " ['HMM', -1.11],\n",
              " ['롯데케미칼', 1.67],\n",
              " ['LG이노텍', -1.07],\n",
              " ['S-Oil', 1.15],\n",
              " ['현대미포조선', 0.79],\n",
              " ['삼성중공업', -0.54],\n",
              " ['고려아연', 0.74],\n",
              " ['한화솔루션', -0.72],\n",
              " ['한국조선해양', -1.38],\n",
              " ['삼성전기', -0.59],\n",
              " ['한미사이언스', 4.96],\n",
              " ['호텔신라', -0.64],\n",
              " ['메리츠증권', -0.91],\n",
              " ['GS리테일', -2.5],\n",
              " ['미래에셋증권', -0.66],\n",
              " ['삼성SDI', -3.9],\n",
              " ['녹십자', -0.95],\n",
              " ['NH투자증권', -0.67],\n",
              " ['GS건설', -2.23],\n",
              " ['삼성전자', -5.52],\n",
              " ['DB손해보험', 0.97],\n",
              " ['POSCO', -3.11],\n",
              " ['현대차', -1.11],\n",
              " ['롯데지주', 0.69],\n",
              " ['현대제철', -1.14],\n",
              " ['포스코케미칼', 0.26],\n",
              " ['한국전력', -1.91],\n",
              " ['SK텔레콤', -4.18],\n",
              " ['삼성증권', -0.9],\n",
              " ['삼성에스디에스', -2.28],\n",
              " ['삼성엔지니어링', -0.55],\n",
              " ['LG유플러스', -0.77],\n",
              " ['삼성카드', -2.63],\n",
              " ['KT', -2.9],\n",
              " ['팬오션', -0.25],\n",
              " ['일진머티리얼즈', -1.23],\n",
              " ['삼성물산', -1.3],\n",
              " ['기업은행', 4.02],\n",
              " ['신풍제약', -1.37],\n",
              " ['한온시스템', 0.75],\n",
              " ['코웨이', 4.16],\n",
              " ['SK이노베이션', -1.03],\n",
              " ['아모레퍼시픽', -0.62],\n",
              " ['맥쿼리인프라', -1.02],\n",
              " ['현대글로비스', -4.53],\n",
              " ['하나금융지주', -2.13],\n",
              " ['휠라홀딩스', 2.76],\n",
              " ['GS', 0.6],\n",
              " ['한국금융지주', -4.61],\n",
              " ['셀트리온', 1.73],\n",
              " ['LG전자', -4.56],\n",
              " ['신한지주', -1.12],\n",
              " ['LG화학', -0.64],\n",
              " ['LG생활건강', 4.12],\n",
              " ['한국항공우주', 1.37],\n",
              " ['대우건설', -1.35],\n",
              " ['엔씨소프트', -1.87],\n",
              " ['대우조선해양', -0.65],\n",
              " ['한국가스공사', -1.09],\n",
              " ['카카오', 3.23],\n",
              " ['NAVER', 0.55],\n",
              " ['강원랜드', -0.63],\n",
              " ['SK', 1.48],\n",
              " ['KT&G', 1.67],\n",
              " ['LG디스플레이', 2.75],\n",
              " ['두산중공업', -1.61],\n",
              " ['삼성생명', -1.69],\n",
              " ['한진칼', -1.02],\n",
              " ['두산밥캣', -1.49],\n",
              " ['삼성바이오로직스', -2.17],\n",
              " ['이마트', -0.87],\n",
              " ['한미약품', 1.26],\n",
              " ['CJ제일제당', -3.03],\n",
              " ['KB금융', 0.73]]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxkPtxj9-dgb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}